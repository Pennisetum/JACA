% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/JACA_mian_functions.R
\name{jacaTrain}
\alias{jacaTrain}
\title{Solve Joint Association and Classification Analysis problem for multi-view data.}
\usage{
jacaTrain(Z, X_list, lambda, rho, missing = F, alpha = 0.5,
  W_list = NULL, kmax = 500, eps = 1e-06, verbose = F)
}
\arguments{
\item{Z}{An N by K class indicator matrix; rows are samples and columns are class indicator vectors with z_k = 1 if observation belongs to class k.}

\item{X_list}{A list of input data matrix; in each sublist, rows are samples and columns are features.}

\item{lambda}{A vector of L1 penalty parameters; if there are D input data matrices, lambda should also contain D elements. \code{lambda} controls the sparsity of the solutions and must be between 0 and 1 (small L1 bound corresponds to less penalization).}

\item{rho}{Scaler, l2 regularization penulty parameter on X'X/n. Should also  be between 0 and 1 (small L2 bound corresponds to less penalization).}

\item{missing}{Logical. If False, input data \code{X_list} must be complete and have no missing values.
If True, input data \code{X_list} should contain missing values.}

\item{alpha}{The parameter to control the weight between optimal scoring and CCA part. Default is 0.5.}

\item{W_list}{A list of inital guess of matrices of discriminant vectors (can be served as a warm start).}

\item{kmax}{Max iteration number.}

\item{eps}{Threashold value used to determine the convergence of the optimization algorithm; the default value is 1e-06.}

\item{verbose}{Logical. If False, the algorithm will stay silent. If True, it will print out fitting progress.}
}
\value{
\item{W_d}{A list of view-specific matrices of discriminant vectors.}
}
\description{
Given Class indicator matrix Z and a list of matrices X_list,
\code{jacaTrain} estimates view-specific matrices of discriminant vectors by solving
Joint Association and Classification Analysis problem. It can also be used to perform semi-supervised learning,
that is to use information from both labeled and unlabeled subjects to construct classification rules.
}
\examples{
set.seed(1)
# generate class indicator matrix Z
n = 100
Z=matrix(c(rep(1, n),rep(0, 2 * n)), byrow = FALSE, nrow = n)
for(i in 1:n){
 Z[i, ] = sample(Z[i, ])
}

# generate input data
d = 2
X_list = sapply(1:d, function(i) list(matrix(rnorm(n * 20), n, 20)))

# train the model
jacaTrain(Z, X_list, lambda = rep(0.05, 2), verbose = FALSE, alpha= 0.5, rho = 0.2)

# test semi supervised learning
Z[90:100, ] = rep(NA, 3)
X_list[[1]][1:10, ] = NA
X_list[[2]][11:20, ] = NA
jacaTrain(Z, X_list, kmax = 200, eps = 1e-06, lambda = rep(0.05, 2),alpha = 0.5, rho = 0.2, missing = TRUE)

}
