% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/JACA_mian_functions.R
\name{jacaCV}
\alias{jacaCV}
\title{Cross-validation function for JACA}
\usage{
jacaCV(
  Z,
  X_list,
  nfolds = 5,
  lambda_seq = NULL,
  n_lambda = 50,
  rho_seq = seq(0.01, 1, length = 20),
  n_rho = 5,
  missing = F,
  alpha = 0.5,
  W_list = NULL,
  kmax = 500,
  eps = 1e-06,
  verbose = F,
  foldID = NULL
)
}
\arguments{
\item{Z}{An N by K class indicator matrix; rows are samples and columns are class indicator vectors with z_k = 1 if observation belongs to class k.}

\item{X_list}{A list of input data matrices; in each sublist, rows are samples and columns are features.}

\item{nfolds}{Number of cross-validation folds.}

\item{lambda_seq}{The set of L1 penalty parameters to be considered. Should be chosen from 0 to 1.
The default value is NULL and \code{jacaCV} generates its own sequence.}

\item{n_lambda}{The number of \code{lambda_seq} considered. Used only if \code{lambda_seq = NULL}.}

\item{rho_seq}{The set of L2 penalty parameters to be considered. Should be chosen from 0 to 1.}

\item{n_rho}{The number of \code{rho_seq} considered. Used only if \code{rho_seq = NULL}.}

\item{missing}{Logical. If False, input data \code{X_list} must be complete and have no missing values.
If True, input data \code{X_list} should contain missing values.}

\item{alpha}{The parameter to control the weight between optimal scoring and CCA part. Default is 0.5.}

\item{W_list}{A list of inital guess of matrices of discriminant vectors (can be served as a warm start).}

\item{kmax}{Max iteration number.}

\item{eps}{Threashold value used to determine the convergence of the optimization algorithm; the default value is 1e-06.}

\item{verbose}{Logical. If False, the algorithm will stay silent. If True, it will print out fitting progress.}

\item{foldID}{User-supplied fold seperation. The default is NULL, and \code{jacaCV} generates its own folds.}
}
\value{
\item{W_min}{A list of view-specific matrices of discriminant vectors. Generated using the parameters chosen by cross-validation method.}

\item{lambda_min}{The value of L1 penalty parameter that resulted in the minimal mean cross-validation error.}

\item{rho_min}{The value of L2 penalty parameter that resulted in the minimal mean cross-validation error.}

\item{grid_seq}{The matrix of tuning parameters used.}

\item{error_mean}{The mean cross-validated error of each combination of the tuning parameters.}

\item{error_se}{The standard error of cross-validated error of each combination of the tuning parameters.}
}
\description{
Chooses optimal tuning parameters lambda and rho for function \code{jacaTrain} using cross-validation.
}
\examples{
set.seed(1)
# Generate class indicator matrix Z
n = 500
Z = matrix(c(rep(1, n),rep(0, 2 * n)), byrow = FALSE, nrow = n)
for(i in 1:n){
  Z[i, ] = sample(Z[i, ])
}

# Generate input data X_list
d = 2
X_list = sapply(1:d, function(i) list(matrix(rnorm(n * 20), n, 20)))
id <- 1:nrow(Z)

# Train JACA model using cross validation
result = jacaCV(Z, X_list, nfolds = 3, lambda_seq = c(0.02, 0.04), rho_seq = c(0.3, 0.6))$W_min

# Test semi supervised learning
# Set certain class labels and subsets of views as missing
Z[90:100, ] = rep(NA, 3)
X_list[[1]][1:10, ] = NA
X_list[[2]][11:20, ] = NA

# Train JACA model using cross validation
result = jacaCV(Z, X_list, nfolds = 3, lambda_seq = c(0.02, 0.04),
                rho_seq = c(0.3, 0.6), missing = TRUE)$W_min

}
